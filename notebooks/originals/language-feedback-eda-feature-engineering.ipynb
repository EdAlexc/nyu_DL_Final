{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport nltk # Tool for text analysis\nfrom nltk import word_tokenize # For total number of words and modeling challenges\nfrom wordcloud import WordCloud # Visualization of the most representative words\nfrom pandas.api.types import CategoricalDtype # Later data treatment\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-11T05:07:10.686811Z","iopub.execute_input":"2022-12-11T05:07:10.687201Z","iopub.status.idle":"2022-12-11T05:07:11.793673Z","shell.execute_reply.started":"2022-12-11T05:07:10.687125Z","shell.execute_reply":"2022-12-11T05:07:11.792677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset Information","metadata":{}},{"cell_type":"code","source":"#Train dataset\ntrain=pd.read_csv(\"/kaggle/input/feedback-prize-english-language-learning/train.csv\")\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-12-11T05:07:11.795603Z","iopub.execute_input":"2022-12-11T05:07:11.796079Z","iopub.status.idle":"2022-12-11T05:07:12.005337Z","shell.execute_reply.started":"2022-12-11T05:07:11.796047Z","shell.execute_reply":"2022-12-11T05:07:12.004466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test=pd.read_csv(\"/kaggle/input/feedback-prize-english-language-learning/test.csv\")\ntest","metadata":{"execution":{"iopub.status.busy":"2022-12-11T05:07:12.006533Z","iopub.execute_input":"2022-12-11T05:07:12.007003Z","iopub.status.idle":"2022-12-11T05:07:12.020186Z","shell.execute_reply.started":"2022-12-11T05:07:12.006973Z","shell.execute_reply":"2022-12-11T05:07:12.019623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For additional insights, the describe function was used, identifying that the mean of all of the categories is close to three while the standard deviation is on an average of 0.65. At the same time, with the .info() property it was recognized that there are no null values in any of the columns.","metadata":{}},{"cell_type":"code","source":"# Numerical Analysis\ntrain.describe()","metadata":{"execution":{"iopub.status.busy":"2022-12-11T05:07:12.021159Z","iopub.execute_input":"2022-12-11T05:07:12.021424Z","iopub.status.idle":"2022-12-11T05:07:12.059197Z","shell.execute_reply.started":"2022-12-11T05:07:12.021401Z","shell.execute_reply":"2022-12-11T05:07:12.058394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Dataframe composition\ntrain.info()","metadata":{"execution":{"iopub.status.busy":"2022-12-11T05:07:12.061201Z","iopub.execute_input":"2022-12-11T05:07:12.062015Z","iopub.status.idle":"2022-12-11T05:07:12.075222Z","shell.execute_reply.started":"2022-12-11T05:07:12.061989Z","shell.execute_reply":"2022-12-11T05:07:12.074341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As an additional way of visualizing the data, the seaborn library was used to create the following histograms, showing that all the categories have a similar distribution (close to the normal) and only the vocabulary has a few outliers, representing that the highest and lowest scores there are few texts with those numbers. This implies a challenge in the future prediction.","metadata":{}},{"cell_type":"code","source":"#Analysis of total representarion per category\n\ntrain_scores=train.drop(columns=[\"full_text\",\"text_id\"])\nn=1\nplt.figure(figsize=(15,20))\nfor i in train_scores.columns:\n    #Use of subplot for better presentation\n    plt.subplot(3,2,n)\n    plt.grid()\n    sns.histplot(data=train_scores,x=i)\n    n +=1","metadata":{"execution":{"iopub.status.busy":"2022-12-11T05:07:12.076697Z","iopub.execute_input":"2022-12-11T05:07:12.077027Z","iopub.status.idle":"2022-12-11T05:07:13.296325Z","shell.execute_reply.started":"2022-12-11T05:07:12.076995Z","shell.execute_reply":"2022-12-11T05:07:13.29532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***","metadata":{}},{"cell_type":"markdown","source":"# Text Analysis","metadata":{}},{"cell_type":"markdown","source":"For an initial look at the database, the total length of each of the texts was calculated through a lambda function and the string function split. With those values, a histogram was plotted, showing that it first looks like a right-skewed distribution as of the effect of the outliers, as the mean is close to 500 words.","metadata":{}},{"cell_type":"code","source":"total_words=train.full_text.apply(lambda x: len(x.split(\" \")))\nplt.figure(figsize=(10,10))\nsns.histplot(total_words)\nplt.grid()\nplt.title(\"Distribution of total text Length\");","metadata":{"execution":{"iopub.status.busy":"2022-12-11T05:07:13.297603Z","iopub.execute_input":"2022-12-11T05:07:13.297901Z","iopub.status.idle":"2022-12-11T05:07:13.916802Z","shell.execute_reply.started":"2022-12-11T05:07:13.297875Z","shell.execute_reply":"2022-12-11T05:07:13.915741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Total mean\ntotal_words.mean()","metadata":{"execution":{"iopub.status.busy":"2022-12-11T05:07:13.9178Z","iopub.execute_input":"2022-12-11T05:07:13.918042Z","iopub.status.idle":"2022-12-11T05:07:13.924265Z","shell.execute_reply.started":"2022-12-11T05:07:13.918018Z","shell.execute_reply":"2022-12-11T05:07:13.922986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, for looking at the general topic of the essays a word cloud was used with all the available words in the text. As expected, the most repeated words correspond to school topics such as student and school.","metadata":{}},{"cell_type":"code","source":"word_cloud_text = ''.join(train.full_text)\n\nwordcloud = WordCloud(\n    max_font_size=100,\n    max_words=100,\n    background_color=\"black\",\n    scale=10,\n    width=800,\n    height=400\n).generate(word_cloud_text)\n\nplt.figure(figsize=(10,10))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-12-11T05:07:13.925802Z","iopub.execute_input":"2022-12-11T05:07:13.926209Z","iopub.status.idle":"2022-12-11T05:07:24.504814Z","shell.execute_reply.started":"2022-12-11T05:07:13.926175Z","shell.execute_reply":"2022-12-11T05:07:24.504179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"With these data, the main text was transformed to lowercase, as a way to be able to compare the different types of words with the list of words from nltk. Then, a word tokenize comparison was made to show the difference of the total unique words making those changes, reducing by almost 3000 tokens.","metadata":{}},{"cell_type":"code","source":"# Lowercase text with string method lower()\ntrain['full_text_low'] = train.full_text.apply(lambda x: x.lower())","metadata":{"execution":{"iopub.status.busy":"2022-12-11T05:07:24.505566Z","iopub.execute_input":"2022-12-11T05:07:24.505794Z","iopub.status.idle":"2022-12-11T05:07:24.519904Z","shell.execute_reply.started":"2022-12-11T05:07:24.505768Z","shell.execute_reply":"2022-12-11T05:07:24.518522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Creation of unique tokens\ntoken_lists = [word_tokenize(each) for each in train.full_text]\ntokens = [item for sublist in token_lists for item in sublist]\nprint(\"Number of unique tokens: \", len(set(tokens)))","metadata":{"execution":{"iopub.status.busy":"2022-12-11T05:07:24.521424Z","iopub.execute_input":"2022-12-11T05:07:24.521778Z","iopub.status.idle":"2022-12-11T05:07:34.040062Z","shell.execute_reply.started":"2022-12-11T05:07:24.521752Z","shell.execute_reply":"2022-12-11T05:07:34.039359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Number of unique words with the lowercase transformation\ntoken_lists_lower = [word_tokenize(each) for each in train.full_text_low]\ntokens_lower = [item for sublist in token_lists_lower for item in sublist]\nprint(\"Number of unique tokens with lowercase: \", len(set(tokens_lower)))","metadata":{"execution":{"iopub.status.busy":"2022-12-11T05:07:34.041174Z","iopub.execute_input":"2022-12-11T05:07:34.042229Z","iopub.status.idle":"2022-12-11T05:07:43.605233Z","shell.execute_reply.started":"2022-12-11T05:07:34.042198Z","shell.execute_reply":"2022-12-11T05:07:43.604326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After this, from nltk, the stopwords from English were loaded. For example, they correspond to I, me, and other types of pronouns. With these data, the final plots were made, as a way to identify features that could affect the score in each of the categories.","metadata":{}},{"cell_type":"code","source":"#Download of stopwords\nnltk.download('stopwords')\nstopwords_corpus = nltk.corpus.stopwords\neng_stop_words = stopwords_corpus.words('english')\nprint(len(eng_stop_words))\neng_stop_words[:10]","metadata":{"execution":{"iopub.status.busy":"2022-12-11T05:07:43.606258Z","iopub.execute_input":"2022-12-11T05:07:43.606598Z","iopub.status.idle":"2022-12-11T05:07:43.777206Z","shell.execute_reply.started":"2022-12-11T05:07:43.606572Z","shell.execute_reply":"2022-12-11T05:07:43.776269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***","metadata":{}},{"cell_type":"markdown","source":"# Feature Engineering and EDA","metadata":{}},{"cell_type":"markdown","source":"Finally, two columns were added to the main dataframe, corresponding to the total length of each of the essays and the total number of stopwords.","metadata":{}},{"cell_type":"code","source":"# Length of texts\ntrain[\"Length\"]=train.full_text.apply(lambda x: len(x.split(\" \")))\n# Total number of stopwords\ntrain[\"Stopwords\"]=train.full_text_low.apply(lambda x: len([w for w in x.split(\" \") if w in eng_stop_words]))","metadata":{"execution":{"iopub.status.busy":"2022-12-11T05:07:43.781053Z","iopub.execute_input":"2022-12-11T05:07:43.78136Z","iopub.status.idle":"2022-12-11T05:07:47.251351Z","shell.execute_reply.started":"2022-12-11T05:07:43.781336Z","shell.execute_reply":"2022-12-11T05:07:47.25041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Additionally, the score columns were transformed to categorical as a way to build the final boxplots.","metadata":{}},{"cell_type":"code","source":"# Category object\ntype_at=CategoricalDtype(ordered=True)\n# Train dataframe transformation\nanalysis_columns=[\"cohesion\",\"syntax\",\"vocabulary\",\"phraseology\",\"grammar\",\"conventions\"]\nfor i in analysis_columns:\n    train[i]=train[i].astype(type_at)\ntrain.info()","metadata":{"execution":{"iopub.status.busy":"2022-12-11T05:07:47.252431Z","iopub.execute_input":"2022-12-11T05:07:47.252693Z","iopub.status.idle":"2022-12-11T05:07:47.271699Z","shell.execute_reply.started":"2022-12-11T05:07:47.252669Z","shell.execute_reply":"2022-12-11T05:07:47.270953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Then, the first group of plots corresponds to the relation between the length of the essays and the scores. As an initial insight, the mean length of each of the categories increases as the score is higher, however, there are a lot of outliers that could affect the development of future models.\n\nAt the same time, the next group of plots that represent the relation between the number of stopwords and the score shows a more evident relation between these values even when there are also a big number of outliers.","metadata":{}},{"cell_type":"code","source":"# Relation between length and score\nplt.figure(figsize=(15,20))\nn=1\nfor i in analysis_columns:\n    plt.subplot(3,2,n)\n    plt.grid()\n    sns.boxplot(data=train,x=\"Length\",y=i)\n    n +=1","metadata":{"execution":{"iopub.status.busy":"2022-12-11T05:07:47.27277Z","iopub.execute_input":"2022-12-11T05:07:47.273761Z","iopub.status.idle":"2022-12-11T05:07:48.460582Z","shell.execute_reply.started":"2022-12-11T05:07:47.273717Z","shell.execute_reply":"2022-12-11T05:07:48.45947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Relation between number of stopwords and score\nplt.figure(figsize=(15,20))\nn=1\nfor i in analysis_columns:\n    plt.subplot(3,2,n)\n    plt.grid()\n    sns.boxplot(data=train,x=\"Stopwords\",y=i)\n    n +=1","metadata":{"execution":{"iopub.status.busy":"2022-12-11T05:07:48.461848Z","iopub.execute_input":"2022-12-11T05:07:48.462171Z","iopub.status.idle":"2022-12-11T05:07:49.872192Z","shell.execute_reply.started":"2022-12-11T05:07:48.462142Z","shell.execute_reply":"2022-12-11T05:07:49.871053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***","metadata":{}},{"cell_type":"markdown","source":"# Conclusions","metadata":{}},{"cell_type":"markdown","source":"* The essay length seems to be an important factor that is related to the total score of each of the 6 categories, but with a high number of outliers.\n* The number of stopwords has a similar trend, that could be used for future modeling.\n* There is a great number of unique words (more than 20000) that need to be considered in the model construction.\n* The total values for each category follow a normal distribution, being an important fact for using statistical modeling.\n***","metadata":{}},{"cell_type":"markdown","source":"--------  Please do Upvote if you liked my work ------------","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}