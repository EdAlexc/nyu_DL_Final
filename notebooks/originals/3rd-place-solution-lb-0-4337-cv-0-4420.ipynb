{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 3rd Place Solution - Feedback Prize English Language Learning\nThis notebook is team \"Now You See Me\" 3rd place solution to Kaggle's Feedback Prize English Language Learning competition. Team members are\n* Amed ( @amedprof )\n* CroDoc ( @crodoc )\n* Chris Deotte ( @cdeotte )\n\nOur solution is an ensemble of 24 NLP models. There are 19 deberta-v3-large, 2 roberta-large, 2 deberta-v3-base, and 1 RAPIDS SVR. The models are all very diverse because they use different pooling methods, different pretraining, different learning schedules, etc. The ensemble was choosen from 50+ models using hill climbing ensemble technique. Our full solution write up is [here][1]\n\n[1]: https://www.kaggle.com/competitions/feedback-prize-english-language-learning/discussion/369609","metadata":{}},{"cell_type":"markdown","source":"# Select Models\nUse `NUM_MODELS=24` to include SVR and TF models. Use `NUM_MODEL=22` to use only PyTorch models.","metadata":{}},{"cell_type":"code","source":"# use either 22 or 24\nNUM_MODELS = 24\n\nimport numpy as np\nnp.save('num_models',NUM_MODELS) #because variables will be erased","metadata":{"execution":{"iopub.status.busy":"2022-12-14T16:58:44.767372Z","iopub.execute_input":"2022-12-14T16:58:44.768324Z","iopub.status.idle":"2022-12-14T16:58:44.773654Z","shell.execute_reply.started":"2022-12-14T16:58:44.768288Z","shell.execute_reply":"2022-12-14T16:58:44.772395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SVR Model\nfrom Chris Deotte's notebook [here][1]\n\n[1]: https://www.kaggle.com/code/cdeotte/rapids-svr-cv-0-450-lb-0-44x","metadata":{}},{"cell_type":"code","source":"if NUM_MODELS==24:\n    %run /kaggle/input/fp3ensemblescripts/rapids-svr-cv-0-450.ipynb\n    %reset -f\n    !mv submission.csv submission_svr1.csv\n    import glob\n    for f in glob.glob('*'):\n        if (not f.startswith('submission'))&(not f.startswith('num_models')):\n            !rm -rf {f}\n            \nimport numpy as np #because variables were be erased\nNUM_MODELS = np.load('num_models.npy').item() ","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-12-14T16:53:18.688512Z","iopub.execute_input":"2022-12-14T16:53:18.689497Z","iopub.status.idle":"2022-12-14T16:56:16.651041Z","shell.execute_reply.started":"2022-12-14T16:53:18.689458Z","shell.execute_reply":"2022-12-14T16:56:16.649751Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TF Model\nfrom Xiang's notebook [here][2]\n\n[2]: https://www.kaggle.com/code/electro/deberta-layerwiselr-lastlayerreinit-tensorflow","metadata":{}},{"cell_type":"code","source":"if NUM_MODELS==24:\n    !python -W ignore /kaggle/input/fp3ensemblescripts/TF-deberta-v3-base-CV-0-455.py\n    !mv submission.csv submission_tf.csv\n    import glob\n    for f in glob.glob('*'):\n        if not f.startswith('submission'):\n            !rm -rf {f}","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-12-14T17:00:55.941202Z","iopub.execute_input":"2022-12-14T17:00:55.941581Z","iopub.status.idle":"2022-12-14T17:04:07.227919Z","shell.execute_reply.started":"2022-12-14T17:00:55.941547Z","shell.execute_reply":"2022-12-14T17:04:07.226327Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transformer Models\ntrained offline by team \"Now You See Me\".","metadata":{}},{"cell_type":"code","source":"import transformers\nprint('Transformers version',transformers.__version__)\n\nimport sys, os,yaml\nsys.path.insert(0, \"/kaggle/input/amed-github-src2/src\")","metadata":{"execution":{"iopub.status.busy":"2022-12-14T17:05:14.969816Z","iopub.execute_input":"2022-12-14T17:05:14.97018Z","iopub.status.idle":"2022-12-14T17:05:14.976425Z","shell.execute_reply.started":"2022-12-14T17:05:14.97015Z","shell.execute_reply":"2022-12-14T17:05:14.975336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport gc \nimport json\nimport joblib\nimport numpy as np\nfrom tqdm.notebook import tqdm\nfrom data.data_utils import batch_to_device,clean_text\nfrom ml.embeddings import get_embeddings,prediction_lgbm\nfrom train_utils import prediction_step\n\nfrom types import SimpleNamespace\nfrom transformers import DataCollatorWithPadding\nfrom transformers import AutoTokenizer, AutoModel, AutoConfig\n\nfrom utils.utils import save_pickle,load_pickle,make_sub,Path,pd\n%env TOKENIZERS_PARALLELISM = true","metadata":{"execution":{"iopub.status.busy":"2022-12-14T17:05:17.173323Z","iopub.execute_input":"2022-12-14T17:05:17.174507Z","iopub.status.idle":"2022-12-14T17:05:19.886417Z","shell.execute_reply.started":"2022-12-14T17:05:17.174459Z","shell.execute_reply":"2022-12-14T17:05:19.88527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 4\n\nDEBUG = False\nFolds = [0]\nfold_name = \"fold_k_5_seed_42\"\n\ndef mcrmse(targets, predictions):\n    error = targets - predictions\n    squared_error = np.square(error)\n    colwise_mse = np.mean(squared_error, axis=0)\n    root_colwise_mse = np.sqrt(colwise_mse)\n    return np.mean(root_colwise_mse, axis=0)\n\nTARGET = ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar','conventions']\n\nif DEBUG:\n    test_df = pd.read_csv(\"../input/feedback-prize-english-language-learning/train.csv\")\n    test_df = test_df.merge(pd.read_csv(\"../input/fp3-blending-weight/df_folds.csv\"),how='left',on=\"text_id\")\n    test_df = test_df[test_df[fold_name].isin(Folds)].reset_index(drop=True)\nelse:\n    test_df = pd.read_csv(\"../input/feedback-prize-english-language-learning/test.csv\")\n\nprint( test_df.shape )\ntest_df.head(2)","metadata":{"execution":{"iopub.status.busy":"2022-12-14T17:05:21.371344Z","iopub.execute_input":"2022-12-14T17:05:21.37205Z","iopub.status.idle":"2022-12-14T17:05:21.395914Z","shell.execute_reply.started":"2022-12-14T17:05:21.372013Z","shell.execute_reply":"2022-12-14T17:05:21.395024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Infer Transformers","metadata":{}},{"cell_type":"code","source":"def predict_folder(test_df,folder,name,bs=1,max_len=640,IDX=0):\n    f = open(f'{folder}/params.json')\n    args = json.load(f)\n    args = SimpleNamespace(**args)\n    args.model['pretrained_config'] = f\"{folder}/config.pth\"\n    args.model['pretrained_tokenizer'] = f\"{folder}/tokenizer/tokenizer\"\n    args.val_loader['batch_size'] = bs\n    args.model['max_len_eval'] = max_len\n    args.model['max_len'] = max_len\n    args.model['additional_features'] = []\n    args.val_loader['num_workers'] = os.cpu_count()-1\n    try:\n        s = args.model['spans pooling params']\n    except:\n        args.model['spans pooling params'] = \"\"\n        args.model['spans'] = \"\"\n            \n    args.device = 0\n    f.close()\n    if DEBUG:\n        checkpoints = [x.as_posix() for x in (Path(folder)).glob(\"*.pth\") if (('fold_0' in str(x))|('fold0' in str(x)))]\n        return prediction_step(args,test_df.copy(),checkpoints=checkpoints,weights=[1/len(checkpoints)]*len(checkpoints))\n    else:\n        checkpoints = [x.as_posix() for x in (Path(folder)).glob(\"*.pth\") if 'config' not in str(x)]\n        if len(checkpoints) != 5:\n            print(f'=> ERROR (only {len(checkpoints)}) not 5 folds in',folder)\n        prediction_step(args,test_df.copy(),checkpoints=checkpoints,weights=[1/len(checkpoints)]*len(checkpoints)).to_csv(f'submission_{name}.csv',index=False)\n        gc.collect()\n    \ndef read_n_sort(path_file):\n    df = pd.read_csv(path_file).sort_values('text_id').reset_index(drop=True)\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-12-14T17:05:25.115707Z","iopub.execute_input":"2022-12-14T17:05:25.116761Z","iopub.status.idle":"2022-12-14T17:05:25.131611Z","shell.execute_reply.started":"2022-12-14T17:05:25.116716Z","shell.execute_reply":"2022-12-14T17:05:25.130523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define Map Model Names to Kaggle Datasets","metadata":{}},{"cell_type":"code","source":"names = ['oof_deberta-v3-large_psl-dv3l-08-10-2022--01_0.4388_bs_1_ml_640.csv',\n       'oof_deberta-v3-large_psl-dv3l-01-11-2022--01_0.4390_bs_1_ml_640.csv',\n       'oof_deberta-v3-large-squad2_psl-dv3lsq-01-11-2022--01_0.4399_bs_1_ml_640.csv',\n       'oof_deberta-large_psl-dl-01-11-2022--01_0.4410_bs_1_ml_640.csv',\n       'oof_deberta-v3-base_psl-dv3b-01-11-2022--01_0.4425_bs_1_ml_640.csv',\n       'oof_deberta-v3-large-squad2_dv3ls-cls-12-10-2022--02_0.4524_bs_1_ml_640.csv',\n       'oof_deberta-v3-large-squad2_dv3ls-cls-14-10-2022--02_0.4525_bs_1_ml_640.csv',\n       'oof_deberta-v3-large_dv3l-14-10-2022--01_0.4495_bs_1_ml_640.csv',\n       'oof_deberta-v3-large_dv3l-cls-15-10-2022--03_0.4509_bs_1_ml_640.csv',\n       'oof_roberta-large-ner-english_jb-GradNorm-MeanP-02-10-2022--01_0.4571_bs_1_ml_640.csv',\n       'oof_deberta-v3-large_dv3l-GradNorm-CLS-04-10-2022--04_0.4515_bs_1_ml_640.csv',\n       'oof_deberta-v3-large_sentences-att-mp-13-11-2022---01_0.4528_bs_1_ml_640.csv',\n       'oof_deberta-v3-large_dv3l-mp-fc-15-10-2022--02_0.4503_bs_1_ml_640.csv',\n       'oof_deberta-v3-base_psl-dv3b-10-10-2022--02_0.4437_bs_1_ml_640.csv',\n       'oof_deberta-v3-large_dv3l-GradNorm-MP-04-10-2022--05_0.4492_bs_1_ml_640.csv',\n       'oof_deberta-large_MeanP-01-10-2022--01_0.4542_bs_1_ml_640.csv',\n       'oof_deberta-v3-large_dv3l-mp-15-10-2022--03_0.4508_bs_1_ml_640.csv',\n       'oof_deberta-v3-large-squad2_dv3ls-12-10-2022--02_0.4565_bs_1_ml_640.csv',\n       'oof_deberta-v3-large_dv3l-GradNorm-MeanP-03-10-2022--01_0.4491_bs_1_ml_640.csv',\n       'oof_deberta-v3-base_dv3b-GradNorm-MeanP-02-10-2022--01_0.4575_bs_1_ml_640.csv',\n       'oof_deberta-v3-large_dv3l-12-10-2022--02_0.4522_bs_1_ml_640.csv',\n       'oof_deberta-v3-large_dv3l-mp-17-10-2022--01_0.4512_bs_1_ml_640.csv',\n       'oof_deberta-v3-large_words-att-mp-13-11-2022---01_0.4574_bs_1_ml_640.csv',\n       'oof_deberta-v3-large_paragraph-att-mp-13-11-2022---01_0.4527_bs_1_ml_640.csv',\n       'oof_deberta-v3-large-squad2_dv3ls-14-10-2022--01_0.4570_bs_1_ml_640.csv',\n       'oof_deberta-v3-large_psl-18m-dv3l-21-11-2022--01_0.4396_bs_1_ml_640_cd.csv', \n       'oof_deberta-v3-base_psl-18m-dv3l-21-11-2022--01-base_0.4415_bs_1_ml_640_cd.csv', \n       'oof_deberta-v3-large_MeanP-01-10-2022--01_0.4498_bs_1_ml_640.csv',\n       'oof_deberta-v3-large_dv3l-mp-fc-15-10-2022--01_0.4516_bs_1_ml_640.csv',\n       'oof_deberta-v3-large_psl-dv3l-08-10-2022--02_0.4396_bs_1_ml_640.csv'] \n\nnames += ['oof_deberta-v3-small_clean-deberta-v3-small_0.4567_bs_1_ml_640_cd3.csv', \n          'oof_deberta-v3-small_attention-deberta-v3-small_0.4575_bs_1_ml_640_cd3.csv'] \n\nnames += ['oof_deberta-large-mnli_dmnl-GradNorm-MP-03-10-2022--01_0.4548_bs_1_ml_640.csv',\n       'oof_deberta-v3-large-squad2_dv3ls-12-10-2022--01_0.4501_bs_1_ml_640.csv',\n       'oof_deberta-v3-large_dv3l-12-10-2022--01_0.4500_bs_1_ml_640.csv',\n       'oof_deberta-v3-large_dv3l-14-10-2022--02_0.4511_bs_1_ml_640.csv',\n       'oof_deberta-v3-large_dv3l-GradNorm-MeanP-02-10-2022--01_0.4489_bs_1_ml_640.csv',\n       'oof_deberta-v3-large_dv3l-GradNorm-MeanP-04-10-2022--02_0.4500_bs_1_ml_640.csv',\n       'oof_deberta-v3-large_dv3l-cls-29-10-2022--01_0.4502_bs_1_ml_640.csv',\n       'oof_deberta-v3-large_dv3l-cls-29-10-2022--02_0.4509_bs_1_ml_640.csv',\n       'oof_deberta-v3-large_dv3l-mp-19-11-2022--02_0.4470_bs_1_ml_640.csv',\n       'oof_deberta-v3-large_sentences-max-mp-13-11-2022---01_0.4528_bs_1_ml_640.csv',\n       'oof_xlm-roberta-large-finetuned-conll03-english_kaggle_sub_0.4575_bs_1_ml_640.csv',\n       'SVR1_OOF_4526.csv', 'SVR2_OOF_4544.csv', 'TF_OOF_4554.csv']\n\npaths = [\n            \"/kaggle/input/psl-dv3l-08-10-2022-01/psldv3l0810202201\",\n            \"/kaggle/input/psl-dv3l-01-11-2022-01/psldv3l0111202201\",\n            \"/kaggle/input/psl-dv3lsq-01-11-2022-01/psldv3lsq0111202201\",\n            \"/kaggle/input/psl-dl-01-11-2022-01/psldl0111202201\",\n            \"/kaggle/input/psl-dv3b-01-11-2022-01/psldv3b0111202201\",\n            \"/kaggle/input/dv3ls-cls-12-10-2022-02/dv3lscls1210202202\",\n            \"/kaggle/input/dv3ls-cls-14-10-2022-02/dv3lscls1410202202\",\n            \"/kaggle/input/dv3l-14-10-2022-01-0-4495/dv3l1410202201-04495\",\n            \"/kaggle/input/dv3l-cls-15-10-2022-03/dv3lcls1510202203\",\n            \"/kaggle/input/jbgradnormmeanp0210202201\",\n            \"/kaggle/input/dv3l-gradnorm-cls-04-10-2022-04/dv3lgradnormcls0410202204\",\n            \"/kaggle/input/sentences-att-mp-13-11-2022-01/sentencesattmp1311202201\",\n            \"/kaggle/input/dv3l-mp-fc-15-10-2022-02/dv3lmpfc1510202202\",\n            \"/kaggle/input/notebook525f2d2f62/psldv3b1010202202\",\n            \"/kaggle/input/dv3l-gradnorm-mp-04-10-2022-05-0-4494/dv3lgradnormmp0410202205-04494\",\n            \"/kaggle/input/fp3-deberta-large-meanp0110202201\",\n            \"/kaggle/input/dv3l-mp-15-10-2022-03/dv3lmp1510202203\",\n            \"/kaggle/input/dv3ls-12-10-2022-02/dv3ls1210202202\",\n            \"/kaggle/input/dv3lgradnormmeanp0310202201\",\n            \"/kaggle/input/dv3lgradnormmeanp0210202201\",\n            \"/kaggle/input/dv3l-12-10-2022-02/dv3l1210202202\",\n            \"/kaggle/input/dv3l-mp-17-10-2022-01/dv3lmp1710202201\",\n            \"/kaggle/input/words-att-mp-13-11-2022-01/wordsattmp1311202201\",\n            \"/kaggle/input/paragraph-att-mp-13-11-2022-01/paragraphattmp1311202201\",\n            \"/kaggle/input/dv3ls-14-10-2022-01/dv3ls1410202201\",\n            \"/kaggle/input/deberta-v3-large-psl18/debertav3largepsl18\", \n            \"/kaggle/input/deberta-v3-base-18psl/debertav3base18psl\", \n            \"/kaggle/input/fp3-deberta-v3-large-meanp0110202201\",\n            \"/kaggle/input/dv3l-mp-fc-15-10-2022-01/dv3lmpfc1510202201\",\n            \"/kaggle/input/psl-dv3l-08-10-2022-02/psldv3l081020222\"\n] \n\npaths += ['/kaggle/input/clean-deberta-v3-small/cleandebertav3small', \n          '/kaggle/input/attention-deberta-v3-small/attentiondebertav3small'] \n\npaths += ['/kaggle/input/dmnlgradnormmp0310202201',\n       '/kaggle/input/dv3ls-12-10-2022-01-0-4499/dv3ls1210202201-0',\n       '/kaggle/input/dv3l-12-10-2022-01-0-4496/dv3l1210202201-04496',\n       '/kaggle/input/dv3l-14-10-2022-02/dv3l1410202202',\n       '/kaggle/input/dv3lgradnormmeanp0210202201',\n       '/kaggle/input/dv3lgradnormmeanp0410202202',\n       '/kaggle/input/dv3l-cls-29-10-2022-01/dv3lcls2910202201',\n       '/kaggle/input/dv3l-cls-29-10-2022-02/dv3lcls2910202202',\n       '/kaggle/input/dv3l-mp-19-11-2022-02/dv3lmp1911202202',\n       '/kaggle/input/sentences-max-mp-13-11-2022-01/sentencesmaxmp1311202201',\n       '/kaggle/input/fp3-xlmmeanp0210202201',\n       'SVR1_OOF_4526.csv', 'SVR2_OOF_4544.csv', 'TF_OOF_4554.csv']\n\n# NON-PyTorch NLP MODELS\nSKIP = ['SVR1_OOF_4526.csv', 'SVR2_OOF_4544.csv', 'TF_OOF_4554.csv','oof_v1169.csv']\nskip_names = {'SVR1_OOF_4526.csv':'svr1', 'SVR2_OOF_4544.csv':'svr2', 'TF_OOF_4554.csv':'tf','oof_v1169.csv':'chris'}\n\nname2path = {x:y for x,y in zip(names,paths)}","metadata":{"execution":{"iopub.status.busy":"2022-12-14T17:05:28.737255Z","iopub.execute_input":"2022-12-14T17:05:28.737728Z","iopub.status.idle":"2022-12-14T17:05:28.751095Z","shell.execute_reply.started":"2022-12-14T17:05:28.73769Z","shell.execute_reply":"2022-12-14T17:05:28.749693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bss = []\nfor n in names:\n    if ('sentence' in n)|('paragraph' in n)|('word' in n):\n        bss.append(1)\n    else:\n        bss.append(BATCH_SIZE)\nname2bs = {x:y for x,y in zip(names,bss)}\n\nimport pandas as pd\ne_wgt = pd.read_csv(f'/kaggle/input/fp3ensemblescripts/ensemble_{NUM_MODELS}_model_no_psl.csv')\ne_wgt.head()","metadata":{"_kg_hide-output":false,"execution":{"iopub.status.busy":"2022-12-14T17:05:34.257024Z","iopub.execute_input":"2022-12-14T17:05:34.257405Z","iopub.status.idle":"2022-12-14T17:05:34.27543Z","shell.execute_reply.started":"2022-12-14T17:05:34.257353Z","shell.execute_reply":"2022-12-14T17:05:34.274189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"folders = [name2path[x] for x in e_wgt.n.values]\nprint( folders ,'\\n')\n\nweights = list( e_wgt.w.values )\nprint( weights ,'\\n')\n\nBS = [name2bs[x] for x in e_wgt.n.values]\nprint( BS ,'\\n')\n\nnames = [f\"m{i}\" for i in range(len(folders))]\nlen(folders),np.sum(weights),len(weights)","metadata":{"execution":{"iopub.status.busy":"2022-12-14T17:05:57.407483Z","iopub.execute_input":"2022-12-14T17:05:57.407845Z","iopub.status.idle":"2022-12-14T17:05:57.418218Z","shell.execute_reply.started":"2022-12-14T17:05:57.407814Z","shell.execute_reply":"2022-12-14T17:05:57.417087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Infer PyTorch Models","metadata":{}},{"cell_type":"code","source":"if DEBUG:\n    for i,(folder,name,bs) in enumerate(zip(folders,names,BS)):\n        if folder in SKIP: continue\n        res = predict_folder(test_df,folder,name,bs=bs,IDX=i)\n        print(mcrmse(res.sort_values(\"text_id\")[TARGET].values,test_df.sort_values(\"text_id\")[TARGET].values))\nelse:\n    for i,(folder,name,bs) in enumerate(zip(folders,names,BS)):\n        if folder in SKIP: continue\n        predict_folder(test_df,folder,name,bs=bs,IDX=i)","metadata":{"execution":{"iopub.status.busy":"2022-12-14T17:06:38.240708Z","iopub.execute_input":"2022-12-14T17:06:38.241095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Ensemble Submission CSV","metadata":{}},{"cell_type":"code","source":"test_df = test_df.sort_values('text_id').reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-12-14T16:56:16.979979Z","iopub.status.idle":"2022-12-14T16:56:16.980758Z","shell.execute_reply.started":"2022-12-14T16:56:16.980507Z","shell.execute_reply":"2022-12-14T16:56:16.98053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df[TARGET] = 0\nfor f,name,w in zip(folders,names,weights):\n    if f in SKIP: \n        nm = skip_names[f]\n    else: \n        nm = name\n    test_df[TARGET]+=((read_n_sort(f'submission_{nm}.csv')[TARGET].values)*w)\n    os.remove(f'submission_{nm}.csv')","metadata":{"execution":{"iopub.status.busy":"2022-12-14T16:56:16.98217Z","iopub.status.idle":"2022-12-14T16:56:16.982939Z","shell.execute_reply.started":"2022-12-14T16:56:16.982679Z","shell.execute_reply":"2022-12-14T16:56:16.982702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df[[\"text_id\"]+TARGET].to_csv('submission.csv',index=False)\ntest_df[[\"text_id\"]+TARGET].head()","metadata":{"execution":{"iopub.status.busy":"2022-12-14T16:56:16.984306Z","iopub.status.idle":"2022-12-14T16:56:16.985084Z","shell.execute_reply.started":"2022-12-14T16:56:16.984842Z","shell.execute_reply":"2022-12-14T16:56:16.984866Z"},"trusted":true},"execution_count":null,"outputs":[]}]}